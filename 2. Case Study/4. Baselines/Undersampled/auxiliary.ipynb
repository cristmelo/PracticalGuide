{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn import datasets, linear_model\n",
    "\n",
    "from sklearn.feature_selection import RFE, RFECV\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier, LogisticRegressionCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lbm\n",
    "\n",
    "from sklearn.utils import resample\n",
    "\n",
    "from imblearn.over_sampling import SMOTE, ADASYN, RandomOverSampler, BorderlineSMOTE, SMOTENC, SVMSMOTE\n",
    "from imblearn.under_sampling import ClusterCentroids, RandomUnderSampler, NearMiss, EditedNearestNeighbours, InstanceHardnessThreshold, TomekLinks\n",
    "\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import itertools\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#smote_sampler = SMOTE()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    #    print(\"Normalized confusion matrix\")\n",
    "    #else:\n",
    "    #    print('Confusion matrix, without normalization')\n",
    "\n",
    "    #print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    \n",
    "def plot_confusion_matrixes(y_test, y_pred):\n",
    "    # Compute confusion matrix\n",
    "    cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    np.set_printoptions(precision=2)\n",
    "\n",
    "    # Plot non-normalized confusion matrix\n",
    "\n",
    "    plt.figure()\n",
    "    plt.subplots(1,2,figsize=(20,4))\n",
    "    plt.subplot(1,2,1)\n",
    "    plot_confusion_matrix(cnf_matrix, classes=class_names, title='Confusion matrix, without normalization')\n",
    "\n",
    "    # Plot normalized confusion matrix\n",
    "    plt.subplot(1,2,2)\n",
    "    plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True, title='Normalized confusion matrix')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(y_test, y_pred):\n",
    "    scores = []\n",
    "    \n",
    "    scores.append(f1_score(y_test, y_pred, average='micro'))\n",
    "    #print(\"F1-Score(micro): \" + str(scores[-1]))\n",
    "    \n",
    "    scores.append(f1_score(y_test, y_pred, average='macro'))\n",
    "    #print(\"F1-Score(macro): \" + str(scores[-1]))\n",
    "    \n",
    "    scores.append(f1_score(y_test, y_pred, average=None))\n",
    "    #print(\"F1-Score(None): \" + str(scores[-1]))\n",
    "    \n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    \n",
    "    #Sensitivity\n",
    "    sensitivity = tp / (tp+fn)\n",
    "    scores.append(tp / (tp+fn))\n",
    "    #print(\"Sensitivity: \" + str(scores[-1]))\n",
    "    \n",
    "    #Specificity\n",
    "    specificity = tn / (tn+fp)\n",
    "    scores.append (tn / (tn+fp))\n",
    "    #print(\"Specificity: \" + str(scores[-1]))\n",
    "    \n",
    "    #VPP\n",
    "    scores.append(tp / (tp+fp))\n",
    "    #print(\"VPP: \" + str(scores[-1]))\n",
    "    \n",
    "    #VPN\n",
    "    scores.append(tn / (tn+fn))\n",
    "    #print(\"VPN: \" + str(scores[-1]))\n",
    "    \n",
    "    #RVP\n",
    "    scores.append(sensitivity / (1-specificity))\n",
    "    #print(\"RVP: \" + str(scores[-1]))\n",
    "    \n",
    "    #RVN\n",
    "    scores.append((1 - sensitivity) / specificity)\n",
    "    #print(\"RVN: \" + str(scores[-1]))\n",
    "    \n",
    "    #ROC_AUC\n",
    "    scores.append(roc_auc_score(y_test, y_pred))\n",
    "    #print(\"ROC_AUC: \" + str(scores[-1]))\n",
    "        \n",
    "    scores.append([tn, fp, fn, tp])\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PickleToTSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickleToTSV(pickle_file):\n",
    "    #partial_results_baselines_default.pickle\n",
    "    file = open(pickle_file, 'rb')\n",
    "    object_file = pickle.load(file)\n",
    "    file.close()\n",
    "    \n",
    "    for method in object_file.keys():\n",
    "        h = np.zeros((9, 10))\n",
    "\n",
    "        fold_column = 0\n",
    "\n",
    "        for fold in object_file[method].keys():\n",
    "            z = object_file[method][fold][0]\n",
    "            del z[-1]\n",
    "            del z[2]\n",
    "\n",
    "            for metric_index in range(len(z)):\n",
    "                h[metric_index][fold_column] = z[metric_index]\n",
    "\n",
    "            fold_column = fold_column + 1\n",
    "\n",
    "        print(method, end=\"\\t\")\n",
    "        for i in range(9):\n",
    "            print(str(round(np.mean(h[i]), 3)) + \"(± \" + str(round(np.std(h[i]), 3)) + \")\" , end=\"\\t\")\n",
    "        \n",
    "        print(\"\")\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print classifiers data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_classifier_data(classifiers_data):\n",
    "    for i in classifiers_data:\n",
    "        print (\"Metodo aplicado: \" + str(i[0]) + \"; ROC_Treino: \" + str(i[1].best_score_) + \"; ROC_Teste: \" + str(i[3][-1]) + \"; Diferença: \" + str(i[3][-1] - i[1].best_score_ ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outliers_counter(df):\n",
    "\n",
    "    outliers_index_list = list()\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        outlier_counter = 0\n",
    "        if row.CBO > boxplot_max_list[0]:\n",
    "            outlier_counter = outlier_counter + 1\n",
    "\n",
    "        if row.CC > boxplot_max_list[1]:\n",
    "            outlier_counter = outlier_counter + 1\n",
    "\n",
    "        if row.DIT > boxplot_max_list[2]:\n",
    "            outlier_counter = outlier_counter + 1\n",
    "\n",
    "        if row.LCOM > boxplot_max_list[3]:\n",
    "            outlier_counter = outlier_counter + 1\n",
    "\n",
    "        if row.LOC > boxplot_max_list[4]:\n",
    "            outlier_counter = outlier_counter + 1\n",
    "\n",
    "        if row.NOC > boxplot_max_list[5]:\n",
    "            outlier_counter = outlier_counter + 1\n",
    "\n",
    "        if row.RFC > boxplot_max_list[6]:\n",
    "            outlier_counter = outlier_counter + 1\n",
    "\n",
    "        if row.WMC > boxplot_max_list[7]:\n",
    "            outlier_counter = outlier_counter + 1\n",
    "\n",
    "        if outlier_counter >= 4:\n",
    "            outliers_index_list.append(index)\n",
    "    \n",
    "    return outliers_index_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
